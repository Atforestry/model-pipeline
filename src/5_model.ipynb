{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Planet: Understanding the Amazon deforestation from Space \n",
    "\n",
    "Identifying deforestration is an extremely important task for our planet.  For this task we employ machine learning implemented in this notebook.\n",
    "We are using satellite images from [Planet: Understanding th\n",
    "e Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)  Kaggle competition [dataset](https://www.kaggle.com/competitions/planet-understanding-the-amazon-from-space/data). Additionally, we are leveraging the work done by [EKami](https://github.com/EKami/planet-amazon-deforestation), using a VGG16 convolutional model pre-trained with the Imagenet dataset and retrained to predict the type of cover land on top of the satellite images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install necessary packages\n",
    "We have put the dependencies in a `requirements.txt` file so we will use that to install the neccessary packages by running `pip install --user <package_name>`\n",
    "\n",
    "> NOTE: Do not forget to use the `--user` argument. It is necessary if you want to use Kale to transform this notebook into a Kubeflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --user -r requirements_ml.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports\n",
    "In this section we import the packages we need. In the original notebook we use mathplotlib but for the pipeline run we decided that it's not neccessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "#import bcolz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\n",
    "from keras.models import load_model\n",
    "import vgg16\n",
    "import data_helper\n",
    "from data_helper import AmazonPreprocessor\n",
    "from PIL import Image\n",
    "#from kaggle_data.downloader import KaggleDataDownloader\n",
    "\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project hyper-parameters\n",
    "\n",
    "In this cell, we define the different hyper-parameters. Defining them in one place makes it easier to experiment with their values and also facilitates the execution of HP Tuning experiments using Kale and Katib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Print tensorflow version for reuse (the Keras module is used directly from the tensorflow framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "In this section, we load and process the dataset to get it in a ready-to-use form by the model. First, let us load the image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "train_jpeg_dir, test_jpeg_dir, test_jpeg_additional, train_csv_file = data_helper.get_jpeg_data_files_paths()\n",
    "labels_df = pd.read_csv(train_csv_file)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Each image can be tagged with multiple tags, lets list all uniques tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "# Print all unique tags\n",
    "from itertools import chain\n",
    "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\n",
    "labels_set = set(labels_list)\n",
    "print(\"There is {} unique labels including {}\".format(len(labels_set), labels_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Repartition of each labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "# Histogram of label instances\n",
    "labels_s = pd.Series(labels_list).value_counts() # To sort them by count\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.barplot(x=labels_s, y=labels_s.index, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Images\n",
    "Visualize some chip images to know what we are dealing with.\n",
    "Lets vizualise 1 chip for the 17 images to get a sense of their differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "images_title = [labels_df[labels_df['tags'].str.contains(label)].iloc[i]['image_name'] + '.jpg' \n",
    "                for i, label in enumerate(labels_set)]\n",
    "\n",
    "plt.rc('axes', grid=False)\n",
    "_, axs = plt.subplots(5, 4, sharex='col', sharey='row', figsize=(15, 20))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, (image_name, label) in enumerate(zip(images_title, labels_set)):\n",
    "    img = mpimg.imread(train_jpeg_dir + '/' + image_name)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title('{} - {}'.format(image_name, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image resize & validation split\n",
    "Define the dimensions of the image data trained by the network. Recommended resized images could be 32x32, 64x64, or 128x128 to speedup the training. \n",
    "\n",
    "You could also use `None` to use full sized images.\n",
    "\n",
    "Be careful, the higher the `validation_split_size` the more RAM you will consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "img_resize = (128, 128) # The resize size of each image ex: (64, 64) or None to use the default image size\n",
    "validation_split_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess data \n",
    "Due to the hudge amount of memory the preprocessed images can take, we will create a dedicated `AmazonPreprocessor` class which job is to preprocess the data right in time at specific steps (training/inference) so that our RAM don't get completely filled by the preprocessed images. \n",
    "\n",
    "The only exception to this being the validation dataset as we need to use it as-is for f2 score calculation as well as when we calculate the validation accuracy of each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:preprocess_data",
     "prev:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessor = AmazonPreprocessor(train_jpeg_dir, train_csv_file, test_jpeg_dir, test_jpeg_additional, \n",
    "                                  img_resize, validation_split_size)\n",
    "preprocessor.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"X_train/y_train length: {}/{}\".format(len(preprocessor.X_train), len(preprocessor.y_train)))\n",
    "print(\"X_val/y_val length: {}/{}\".format(len(preprocessor.X_val), len(preprocessor.y_val)))\n",
    "print(\"X_test/X_test_filename length: {}/{}\".format(len(preprocessor.X_test), len(preprocessor.X_test_filename)))\n",
    "preprocessor.y_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define and train the model\n",
    "\n",
    "We are now ready to train our model. We use a predefined VGG16 standard architecture and finetune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_training",
     "prev:preprocess_data",
     "limit:nvidia.com/gpu:4"
    ]
   },
   "outputs": [],
   "source": [
    "model = vgg16.create_model(img_dim=(128, 128, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funtune conv layers\n",
    "We will now train all layers in the VGG16 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "callbacks = [history, \n",
    "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-7, verbose=1),\n",
    "             ModelCheckpoint(filepath='weights/weights.best.hdf5', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=True, mode='auto')]\n",
    "\n",
    "X_train, y_train = preprocessor.X_train, preprocessor.y_train\n",
    "X_val, y_val = preprocessor.X_val, preprocessor.y_val\n",
    "\n",
    "batch_size = 128\n",
    "train_generator = preprocessor.get_train_generator(batch_size)\n",
    "steps = len(X_train) / batch_size\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "#previous epochs=25\n",
    "history = model.fit_generator(train_generator, steps, epochs=2, verbose=1, \n",
    "                    validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Best Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights/weights.best.hdf5\")\n",
    "print(\"Weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "model.save('vgg16_trained.h5')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Finally, we are ready to evaluate the model using the two test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Fbeta Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_evaluaton",
     "prev:model_training"
    ]
   },
   "outputs": [],
   "source": [
    "fbeta_score = vgg16.fbeta(model, X_val, y_val)\n",
    "\n",
    "fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "predictions, x_test_filename = vgg16.predict(model, preprocessor, batch_size=128)\n",
    "print(\"Predictions shape: {}\\nFiles name shape: {}\\n1st predictions ({}) entry:\\n{}\".format(predictions.shape, \n",
    "                                                                              x_test_filename.shape,\n",
    "                                                                              x_test_filename[0], predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before mapping our predictions to their appropriate labels we need to figure out what threshold to take for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "thresholds = [0.2] * len(labels_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now lets map our predictions to their tags by using the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "predicted_labels = vgg16.map_predictions(preprocessor, predictions, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally lets assemble and visualize our predictions for the test dataset to run batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "tags_list = [None] * len(predicted_labels)\n",
    "for i, tags in enumerate(predicted_labels):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "print(\"Predictions rows:\", final_df.size)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reload Model and Test Single Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "new_model = load_model('vgg16_trained.h5')\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "image_name = 'train_1.jpg'\n",
    "img = mpimg.imread(train_jpeg_dir + '/' + image_name)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "img_reshape = np.expand_dims(img, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_reshape = np.asarray(Image.fromarray(img).convert(\"RGB\"), dtype=np.float32)\n",
    "img_reshape = cv2.resize(src = img_reshape, dsize=(128, 128))\n",
    "img_reshape = np.expand_dims(img_reshape, axis=0) \n",
    "img_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "prediction = new_model.predict(img_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "labels = list(labels_set)\n",
    "results = prediction[0] > 0.2\n",
    "true_index_values = [i for i, x in enumerate(results) if x]\n",
    "tags_results = [labels[x] for x in true_index_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "tags_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcf37868dd2e37cfc6a295f86406217ebd8eeadbaf435337ca64f8ac09049afe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "docker_image": "gcr.io/arrikto/jupyter-kale-py36@sha256:dd3f92ca66b46d247e4b9b6a9d84ffbb368646263c2e3909473c3b851f3fe198",
   "experiment": {
    "id": "new",
    "name": "experiment3"
   },
   "experiment_name": "experiment3",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "atforestry",
   "snapshot_volumes": true,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:access-rok:true"
   ],
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "atforestry-model-workspace-7t6h8",
     "size": 100,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
